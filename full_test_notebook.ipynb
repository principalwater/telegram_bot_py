{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part that allows to send an e-mail within code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib, ssl\n",
    "\n",
    "port = 465  # For SSL\n",
    "smtp_server = \"smtp.yandex.ru\"\n",
    "sender_email = \"kuzmi-vl@yandex.ru\"  # Enter your address\n",
    "receiver_email = ['*****@gmail.com','kuzmin.vv@yahoo.com']  # Enter receiver address\n",
    "password = \"yourVeryStrongPassw0rd\"\n",
    "message = \"\"\"\\\n",
    "From: kuzmi-vl@yandex.ru\n",
    "To: kuzmin.vv@yahoo.com\n",
    "Subject: Hi there\n",
    "\n",
    "This message is sent from Python.\"\"\"\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
    "    server.login(sender_email, password)\n",
    "    server.sendmail(sender_email, receiver_email, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the google dialogflow chatbot integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query text: Ты молодец!\n",
      "Detected intent: smalltalk.appraisal.well_done\n",
      "Detected intent confidence: 1.0\n",
      "Fulfillment text: Я стараюсь. Спасибо.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dialogflow\n",
    "from google.api_core.exceptions import InvalidArgument\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'small-talk-itgl-*****.json'\n",
    "\n",
    "DIALOGFLOW_PROJECT_ID = 'small-talk-itgl'\n",
    "DIALOGFLOW_LANGUAGE_CODE = 'ru'\n",
    "SESSION_ID = 'me'\n",
    "\n",
    "text_to_be_analyzed = \"Ты молодец!\"\n",
    "\n",
    "session_client = dialogflow.SessionsClient()\n",
    "session = session_client.session_path(DIALOGFLOW_PROJECT_ID, SESSION_ID)\n",
    "text_input = dialogflow.types.TextInput(text=text_to_be_analyzed, language_code=DIALOGFLOW_LANGUAGE_CODE)\n",
    "query_input = dialogflow.types.QueryInput(text=text_input)\n",
    "try:\n",
    "    response = session_client.detect_intent(session=session, query_input=query_input)\n",
    "except InvalidArgument:\n",
    "    raise\n",
    "\n",
    "print(\"Query text:\", response.query_result.query_text)\n",
    "print(\"Detected intent:\", response.query_result.intent.display_name)\n",
    "print(\"Detected intent confidence:\", response.query_result.intent_detection_confidence)\n",
    "print(\"Fulfillment text:\", response.query_result.fulfillment_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional part, which add stackoverflow best answer finder support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "import datetime\n",
    "import smtplib, ssl\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "import apiai, json\n",
    "from stackapi import StackAPI\n",
    "\n",
    "# StackOverFlow integration handler\n",
    "@bot.message_handler(commands=['stack'])\n",
    "def stack_find(message):\n",
    "    try:\n",
    "        answers_hash = {}\n",
    "        # Example ids\n",
    "        ids = [4, 26833209, 30246303, 35022905, 37782149, 38176075, 48553152, 59339862, 60527079]\n",
    "        api_filter = '!9f*CwGV65'\n",
    "\n",
    "        # Call the API\n",
    "        SITE = StackAPI('stackoverflow')\n",
    "        answers = SITE.fetch('questions/{ids}/answers',\n",
    "                     ids = ids,\n",
    "                     sort = 'votes',\n",
    "                     filter = api_filter)\n",
    "\n",
    "        # Find top voted answers\n",
    "        for item in answers['items']:\n",
    "          if not item['question_id'] in answers_hash:\n",
    "            answers_hash[item['question_id']] = [item['answer_id'], item['score']]\n",
    "\n",
    "        # Print information\n",
    "        for question_id, info in answers_hash.items():\n",
    "          bot.reply_to(message, print(f\"The top voted answer for {question_id} is {info[0]} with a score of {info[1]}\"))\n",
    "    except Exception as e:\n",
    "        bot.reply_to(message, \"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top voted answer for 4 is 7 with a score of 507\n",
      "The top voted answer for 26833209 is 26833614 with a score of 8\n",
      "The top voted answer for 35022905 is 35232890 with a score of 4\n",
      "The top voted answer for 59339862 is 59340420 with a score of 4\n",
      "The top voted answer for 30246303 is 30306036 with a score of 3\n",
      "The top voted answer for 38176075 is 38176147 with a score of 3\n",
      "The top voted answer for 37782149 is 37821056 with a score of 1\n",
      "The top voted answer for 48553152 is 48604045 with a score of 1\n",
      "The top voted answer for 60527079 is 61716034 with a score of 1\n"
     ]
    }
   ],
   "source": [
    "from stackapi import StackAPI\n",
    "\n",
    "answers_hash = {}\n",
    "# Example ids\n",
    "ids = [4, 26833209, 30246303, 35022905, 37782149, 38176075, 48553152, 59339862, 60527079]\n",
    "api_filter = '!9f*CwGV65'\n",
    "\n",
    "# Call the API\n",
    "SITE = StackAPI('stackoverflow')\n",
    "answers = SITE.fetch('questions/{ids}/answers',\n",
    "                     ids = ids,\n",
    "                     sort = 'votes',\n",
    "                     filter = api_filter)\n",
    "\n",
    "# Find top voted answers\n",
    "for item in answers['items']:\n",
    "  if not item['question_id'] in answers_hash:\n",
    "    answers_hash[item['question_id']] = [item['answer_id'], item['score']]\n",
    "\n",
    "# Print information\n",
    "for question_id, info in answers_hash.items():\n",
    "  print(f\"The top voted answer for {question_id} is {info[0]} with a score of {info[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final and revised version ever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StackOverFlow integration handler\n",
    "@bot.message_handler(commands=['stack'])\n",
    "def stack_find(message):\n",
    "    try:\n",
    "        answers_hash = {}\n",
    "        # Example ids\n",
    "        #ids = input()\n",
    "        ids = message.text\n",
    "        ids = ids[7:]\n",
    "        api_filter = '!9f*CwGV65'\n",
    "\n",
    "        # Call the API\n",
    "        SITE = StackAPI('stackoverflow')\n",
    "        answers = SITE.fetch('questions/{ids}/answers',\n",
    "                     ids = ids,\n",
    "                     sort = 'votes',\n",
    "                     filter = api_filter)\n",
    "\n",
    "        # Find top voted answers\n",
    "        for item in answers['items']:\n",
    "          if not item['question_id'] in answers_hash:\n",
    "            answers_hash[item['question_id']] = [item['answer_id'], item['score']]\n",
    "\n",
    "        # Print information\n",
    "        for question_id, info in answers_hash.items():\n",
    "          bot.reply_to(message, f\"The top voted answer for {question_id} is {info[0]} with a score of {info[1]}\")\n",
    "    except Exception as e:\n",
    "        bot.reply_to(message, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backoff': 0,\n",
      " 'has_more': False,\n",
      " 'items': [{'accepted_answer_id': 59336298,\n",
      "            'answer_count': 3,\n",
      "            'body': \"<p>I'm working with 3D pointcloud of Lidar. The points \"\n",
      "                    'are given by numpy array that looks like this:</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>points = np.array([[61651921, 416326074, '\n",
      "                    '39805], [61605255, 416360555, 41124], [61664810, '\n",
      "                    '416313743, 39900], [61664837, 416313749, 39910], '\n",
      "                    '[61674456, 416316663, 39503], [61651933, 416326074, '\n",
      "                    '39802], [61679969, 416318049, 39500], [61674494, '\n",
      "                    '416316677, 39508], [61651908, 416326079, 39800], '\n",
      "                    '[61651908, 416326087, 39802], [61664845, 416313738, '\n",
      "                    '39913], [61674480, 416316668, 39503], [61679996, '\n",
      "                    '416318047, 39510], [61605290, 416360572, 41118], '\n",
      "                    '[61605270, 416360565, 41122], [61683939, 416313004, '\n",
      "                    '41052], [61683936, 416313033, 41060], [61679976, '\n",
      "                    '416318044, 39509], [61605279, 416360555, 41109], '\n",
      "                    '[61664837, 416313739, 39915], [61674487, 416316666, '\n",
      "                    '39505], [61679961, 416318035, 39503], [61683943, '\n",
      "                    '416313004, 41054], [61683930, 416313042, 41059]])\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    \"<p><strong>I'd like to keep my data grouped into cubes of \"\n",
      "                    'size <code>50*50*50</code> so that every cube preserves '\n",
      "                    'some hashable index and numpy indices of my '\n",
      "                    '<code>points</code> it contains</strong>. In order to get '\n",
      "                    'splitting, I assign <code>cubes = points \\\\\\\\ 50</code> '\n",
      "                    'which outputs to:</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>cubes = np.array([[1233038, 8326521, 796], '\n",
      "                    '[1232105, 8327211, 822], [1233296, 8326274, 798], '\n",
      "                    '[1233296, 8326274, 798], [1233489, 8326333, 790], '\n",
      "                    '[1233038, 8326521, 796], [1233599, 8326360, 790], '\n",
      "                    '[1233489, 8326333, 790], [1233038, 8326521, 796], '\n",
      "                    '[1233038, 8326521, 796], [1233296, 8326274, 798], '\n",
      "                    '[1233489, 8326333, 790], [1233599, 8326360, 790], '\n",
      "                    '[1232105, 8327211, 822], [1232105, 8327211, 822], '\n",
      "                    '[1233678, 8326260, 821], [1233678, 8326260, 821], '\n",
      "                    '[1233599, 8326360, 790], [1232105, 8327211, 822], '\n",
      "                    '[1233296, 8326274, 798], [1233489, 8326333, 790], '\n",
      "                    '[1233599, 8326360, 790], [1233678, 8326260, 821], '\n",
      "                    '[1233678, 8326260, 821]])\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<h3>My desired output looks like this:</h3>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>{(1232105, 8327211, 822): [1, 13, 14, 18]), \\n'\n",
      "                    '(1233038, 8326521, 796): [0, 5, 8, 9], \\n'\n",
      "                    '(1233296, 8326274, 798): [2, 3, 10, 19], \\n'\n",
      "                    '(1233489, 8326333, 790): [4, 7, 11, 20], \\n'\n",
      "                    '(1233599, 8326360, 790): [6, 12, 17, 21], \\n'\n",
      "                    '(1233678, 8326260, 821): [15, 16, 22, 23]}\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>My real pointcloud contains up to few hundreds of '\n",
      "                    'millions of 3D points. What is the fastest way to do this '\n",
      "                    'kind of grouping?</p>\\n'\n",
      "                    '\\n'\n",
      "                    \"<p>I've tried a majority of various solutions. Here is \"\n",
      "                    'comparison of time compsumption assuming size of points '\n",
      "                    'is arround 20 millions and size of distinct cubes is '\n",
      "                    'arround 1 million:</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<h3>Pandas [tuple(elem) -> np.array(dtype=int64)]</h3>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>import pandas as pd\\n'\n",
      "                    'print(pd.DataFrame(cubes).groupby([0,1,2]).indices)\\n'\n",
      "                    '#takes 9sec\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<h3>Defauldict [elem.tobytes() or tuple -> list]</h3>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>#thanks @abc:\\n'\n",
      "                    'result = defaultdict(list)\\n'\n",
      "                    'for idx, elem in enumerate(cubes):\\n'\n",
      "                    '    result[elem.tobytes()].append(idx) # takes 20.5sec\\n'\n",
      "                    '    # result[elem[0], elem[1], elem[2]].append(idx) '\n",
      "                    '#takes 27sec\\n'\n",
      "                    '    # result[tuple(elem)].append(idx) # takes 50sec\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<h3>numpy_indexed [int -> np.array]</h3>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code># thanks @Eelco Hoogendoorn for his library\\n'\n",
      "                    'values = '\n",
      "                    'npi.group_by(cubes).split(np.arange(len(cubes)))\\n'\n",
      "                    'result = dict(enumerate(values))\\n'\n",
      "                    '# takes 9.8sec\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<h3>Pandas + dimensionality reduction [int -> '\n",
      "                    'np.array(dtype=int64)]</h3>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code># thanks @Divakar for showing numexpr '\n",
      "                    'library:\\n'\n",
      "                    'import numexpr as ne\\n'\n",
      "                    'def dimensionality_reduction(cubes):\\n'\n",
      "                    '    #cubes = cubes - np.min(cubes, axis=0) #in case some '\n",
      "                    'coords are negative \\n'\n",
      "                    '    cubes = cubes.astype(np.int64)\\n'\n",
      "                    '    s0, s1 = cubes[:,0].max()+1, cubes[:,1].max()+1\\n'\n",
      "                    '    d = '\n",
      "                    \"{'s0':s0,'s1':s1,'c0':cubes[:,0],'c1':cubes[:,1],'c2':cubes[:,2]}\\n\"\n",
      "                    \"    c1D = ne.evaluate('c0+c1*s0+c2*s0*s1',d)\\n\"\n",
      "                    '    return c1D\\n'\n",
      "                    'cubes = dimensionality_reduction(cubes)\\n'\n",
      "                    'result = pd.DataFrame(cubes).groupby([0]).indices\\n'\n",
      "                    '# takes 2.5 seconds\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    \"<p>It's possible to download <code>cubes.npz</code> file \"\n",
      "                    '<a '\n",
      "                    'href=\"https://github.com/loijord/lidar_home/blob/master/cubes.npz\" '\n",
      "                    'rel=\"nofollow noreferrer\">here</a> and use a command '\n",
      "                    '</p>\\n'\n",
      "                    '\\n'\n",
      "                    \"<pre><code>cubes = np.load('cubes.npz')['array']\\n\"\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>to check performance time.</p>\\n',\n",
      "            'content_license': 'CC BY-SA 4.0',\n",
      "            'creation_date': 1575838961,\n",
      "            'is_answered': True,\n",
      "            'last_activity_date': 1578534873,\n",
      "            'last_edit_date': 1578534873,\n",
      "            'link': 'https://stackoverflow.com/questions/59239886/what-is-the-fastest-way-to-map-group-names-of-numpy-array-to-indices',\n",
      "            'owner': {'display_name': 'mathfux',\n",
      "                      'link': 'https://stackoverflow.com/users/3044825/mathfux',\n",
      "                      'profile_image': 'https://i.stack.imgur.com/1pPyB.png?s=256&g=1',\n",
      "                      'reputation': 5323,\n",
      "                      'user_id': 3044825,\n",
      "                      'user_type': 'registered'},\n",
      "            'question_id': 59239886,\n",
      "            'score': 10,\n",
      "            'tags': ['python', 'numpy', 'hash', 'grouping', 'lidar'],\n",
      "            'title': 'What is the fastest way to map group names of numpy '\n",
      "                     'array to indices?',\n",
      "            'view_count': 1187}],\n",
      " 'page': 1,\n",
      " 'quota_max': 300,\n",
      " 'quota_remaining': 164,\n",
      " 'total': 0}\n",
      "{'backoff': 0,\n",
      " 'has_more': False,\n",
      " 'items': [{'answer_id': 59336298,\n",
      "            'body': '<h2>Constant number of indices per group</h2>\\n'\n",
      "                    '\\n'\n",
      "                    '<h3>Approach #1</h3>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>We can perform <code>dimensionality-reduction</code> '\n",
      "                    'to reduce <code>cubes</code> to a 1D array. This is based '\n",
      "                    'on a mapping of the given cubes data onto a n-dim grid to '\n",
      "                    'compute the linear-index equivalents, discussed in detail '\n",
      "                    '<a '\n",
      "                    'href=\"https://stackoverflow.com/a/38674038/\"><code>here</code></a>. '\n",
      "                    'Then, based on the uniqueness of those linear indices, we '\n",
      "                    'can segregate unique groups and their corresponding '\n",
      "                    'indices. Hence, following those strategies, we would have '\n",
      "                    'one solution, like so -</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>N = 4 # number of indices per group\\n'\n",
      "                    'c1D = np.ravel_multi_index(cubes.T, cubes.max(0)+1)\\n'\n",
      "                    'sidx = c1D.argsort()\\n'\n",
      "                    'indices = sidx.reshape(-1,N)\\n'\n",
      "                    'unq_groups = cubes[indices[:,0]]\\n'\n",
      "                    '\\n'\n",
      "                    '# If you need in a zipped dictionary format\\n'\n",
      "                    'out = dict(zip(map(tuple,unq_groups), indices))\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p><strong>Alternative #1 :</strong> If the integer '\n",
      "                    'values in <code>cubes</code> are too large, we might want '\n",
      "                    'to do the <code>dimensionality-reduction</code> such that '\n",
      "                    'the dimensions with shorter extent are choosen as the '\n",
      "                    'primary axes. Hence, for those cases, we can modify the '\n",
      "                    'reduction step to get <code>c1D</code>, like so -</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>s1,s2 = cubes[:,:2].max(0)+1\\n'\n",
      "                    's = np.r_[s2,1,s1*s2]\\n'\n",
      "                    'c1D = cubes.dot(s)\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<h3>Approach #2</h3>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>Next up, we can use <a '\n",
      "                    'href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.cKDTree.query.html\" '\n",
      "                    'rel=\"nofollow noreferrer\"><code>Cython-powered '\n",
      "                    'kd-tree</code> for quick nearest-neighbor lookup</a> to '\n",
      "                    'get nearest neighbouring indices and hence solve our case '\n",
      "                    'like so -</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>from scipy.spatial import cKDTree\\n'\n",
      "                    '\\n'\n",
      "                    'idx = cKDTree(cubes).query(cubes, k=N)[1] # N = 4 as '\n",
      "                    'discussed earlier\\n'\n",
      "                    'I = idx[:,0].argsort().reshape(-1,N)[:,0]\\n'\n",
      "                    'unq_groups,indices = cubes[I],idx[I]\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<hr>\\n'\n",
      "                    '\\n'\n",
      "                    '<h2>Generic case : Variable number of indices per '\n",
      "                    'group</h2>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>We will extend the argsort based method with some '\n",
      "                    'splitting to get our desired output, like so -</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>c1D = np.ravel_multi_index(cubes.T, '\n",
      "                    'cubes.max(0)+1)\\n'\n",
      "                    '\\n'\n",
      "                    'sidx = c1D.argsort()\\n'\n",
      "                    'c1Ds = c1D[sidx]\\n'\n",
      "                    'split_idx = '\n",
      "                    'np.flatnonzero(np.r_[True,c1Ds[:-1]!=c1Ds[1:],True])\\n'\n",
      "                    'grps = cubes[sidx[split_idx[:-1]]]\\n'\n",
      "                    '\\n'\n",
      "                    'indices = [sidx[i:j] for (i,j) in '\n",
      "                    'zip(split_idx[:-1],split_idx[1:])]\\n'\n",
      "                    '# If needed as dict o/p\\n'\n",
      "                    'out = dict(zip(map(tuple,grps), indices))\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p><strong>Using 1D versions of groups of '\n",
      "                    '<code>cubes</code> as keys</strong></p>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>We will extend earlier listed method with the groups '\n",
      "                    'of <code>cubes</code> as keys to simplify the process of '\n",
      "                    'dictionary creating and also make it efficient with it, '\n",
      "                    'like so -</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>def numpy1(cubes):\\n'\n",
      "                    '    c1D = np.ravel_multi_index(cubes.T, '\n",
      "                    'cubes.max(0)+1)        \\n'\n",
      "                    '    sidx = c1D.argsort()\\n'\n",
      "                    '    c1Ds = c1D[sidx]\\n'\n",
      "                    '    mask = np.r_[True,c1Ds[:-1]!=c1Ds[1:],True]\\n'\n",
      "                    '    split_idx = np.flatnonzero(mask)\\n'\n",
      "                    '    indices = [sidx[i:j] for (i,j) in '\n",
      "                    'zip(split_idx[:-1],split_idx[1:])]\\n'\n",
      "                    '    out = dict(zip(c1Ds[mask[:-1]],indices))\\n'\n",
      "                    '    return out\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>Next up, we will make use of <code>numba</code> '\n",
      "                    'package to iterate and get to the final hashable '\n",
      "                    'dictionary output. Going with it, there would be two '\n",
      "                    'solutions - One that gets the keys and values separately '\n",
      "                    'using <code>numba</code> and the main calling will zip '\n",
      "                    'and convert to dict, while the other one will create a '\n",
      "                    '<code>numba-supported</code> dict type and hence no extra '\n",
      "                    'work required by the main calling function. </p>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>Thus, we would have first <code>numba</code> solution '\n",
      "                    ':</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>from numba import  njit\\n'\n",
      "                    '\\n'\n",
      "                    '@njit\\n'\n",
      "                    'def _numba1(sidx, c1D):\\n'\n",
      "                    '    out = []\\n'\n",
      "                    '    n = len(sidx)\\n'\n",
      "                    '    start = 0\\n'\n",
      "                    '    grpID = []\\n'\n",
      "                    '    for i in range(1,n):\\n'\n",
      "                    '        if c1D[sidx[i]]!=c1D[sidx[i-1]]:\\n'\n",
      "                    '            out.append(sidx[start:i])\\n'\n",
      "                    '            grpID.append(c1D[sidx[start]])\\n'\n",
      "                    '            start = i\\n'\n",
      "                    '    out.append(sidx[start:])\\n'\n",
      "                    '    grpID.append(c1D[sidx[start]])\\n'\n",
      "                    '    return grpID,out\\n'\n",
      "                    '\\n'\n",
      "                    'def numba1(cubes):\\n'\n",
      "                    '    c1D = np.ravel_multi_index(cubes.T, cubes.max(0)+1)\\n'\n",
      "                    '    sidx = c1D.argsort()\\n'\n",
      "                    '    out = dict(zip(*_numba1(sidx, c1D)))\\n'\n",
      "                    '    return out\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>And second <code>numba</code> solution as :</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>from numba import types\\n'\n",
      "                    'from numba.typed import Dict\\n'\n",
      "                    '\\n'\n",
      "                    'int_array = types.int64[:]\\n'\n",
      "                    '\\n'\n",
      "                    '@njit\\n'\n",
      "                    'def _numba2(sidx, c1D):\\n'\n",
      "                    '    n = len(sidx)\\n'\n",
      "                    '    start = 0\\n'\n",
      "                    '    outt = Dict.empty(\\n'\n",
      "                    '        key_type=types.int64,\\n'\n",
      "                    '        value_type=int_array,\\n'\n",
      "                    '    )\\n'\n",
      "                    '    for i in range(1,n):\\n'\n",
      "                    '        if c1D[sidx[i]]!=c1D[sidx[i-1]]:\\n'\n",
      "                    '            outt[c1D[sidx[start]]] = sidx[start:i]\\n'\n",
      "                    '            start = i\\n'\n",
      "                    '    outt[c1D[sidx[start]]] = sidx[start:]\\n'\n",
      "                    '    return outt\\n'\n",
      "                    '\\n'\n",
      "                    'def numba2(cubes):\\n'\n",
      "                    '    c1D = np.ravel_multi_index(cubes.T, '\n",
      "                    'cubes.max(0)+1)    \\n'\n",
      "                    '    sidx = c1D.argsort()\\n'\n",
      "                    '    out = _numba2(sidx, c1D)\\n'\n",
      "                    '    return out\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>Timings with <code>cubes.npz</code> data -</p>\\n'\n",
      "                    '\\n'\n",
      "                    \"<pre><code>In [4]: cubes = np.load('cubes.npz')['array']\\n\"\n",
      "                    '\\n'\n",
      "                    'In [5]: %timeit numpy1(cubes)\\n'\n",
      "                    '   ...: %timeit numba1(cubes)\\n'\n",
      "                    '   ...: %timeit numba2(cubes)\\n'\n",
      "                    '2.38 s ± 14.7 ms per loop (mean ± std. dev. of 7 runs, 1 '\n",
      "                    'loop each)\\n'\n",
      "                    '2.13 s ± 25.2 ms per loop (mean ± std. dev. of 7 runs, 1 '\n",
      "                    'loop each)\\n'\n",
      "                    '1.8 s ± 5.95 ms per loop (mean ± std. dev. of 7 runs, 1 '\n",
      "                    'loop each)\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p><strong>Alternative #1 :</strong> We can achieve '\n",
      "                    'further speedup with <code>numexpr</code> for large '\n",
      "                    'arrays to compute <code>c1D</code>, like so -</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>import numexpr as ne\\n'\n",
      "                    '\\n'\n",
      "                    's0,s1 = cubes[:,0].max()+1,cubes[:,1].max()+1\\n'\n",
      "                    'd = '\n",
      "                    \"{'s0':s0,'s1':s1,'c0':cubes[:,0],'c1':cubes[:,1],'c2':cubes[:,2]}\\n\"\n",
      "                    \"c1D = ne.evaluate('c0+c1*s0+c2*s0*s1',d)\\n\"\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>This would be applicable at all places that require '\n",
      "                    '<code>c1D</code>.</p>\\n',\n",
      "            'content_license': 'CC BY-SA 4.0',\n",
      "            'creation_date': 1576336051,\n",
      "            'is_accepted': True,\n",
      "            'last_activity_date': 1576442605,\n",
      "            'last_edit_date': 1576442605,\n",
      "            'owner': {'accept_rate': 17,\n",
      "                      'display_name': 'Divakar',\n",
      "                      'link': 'https://stackoverflow.com/users/3293881/divakar',\n",
      "                      'profile_image': 'https://i.stack.imgur.com/6ZYnq.jpg?s=256&g=1',\n",
      "                      'reputation': 212735,\n",
      "                      'user_id': 3293881,\n",
      "                      'user_type': 'registered'},\n",
      "            'question_id': 59239886,\n",
      "            'score': 6},\n",
      "           {'answer_id': 59240241,\n",
      "            'body': '<p>You might just iterate and add the index of each '\n",
      "                    'element to the corresponding list.</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>from collections import defaultdict\\n'\n",
      "                    '\\n'\n",
      "                    'res = defaultdict(list)\\n'\n",
      "                    '\\n'\n",
      "                    'for idx, elem in enumerate(cubes):\\n'\n",
      "                    '    #res[tuple(elem)].append(idx)\\n'\n",
      "                    '    res[elem.tobytes()].append(idx)\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>Runtime can be further improved by using <a '\n",
      "                    'href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tobytes.html\" '\n",
      "                    'rel=\"nofollow noreferrer\">tobytes()</a> instead of '\n",
      "                    'converting the key to a tuple.</p>\\n',\n",
      "            'content_license': 'CC BY-SA 4.0',\n",
      "            'creation_date': 1575842037,\n",
      "            'is_accepted': False,\n",
      "            'last_activity_date': 1576356205,\n",
      "            'last_edit_date': 1576356205,\n",
      "            'owner': {'accept_rate': 86,\n",
      "                      'display_name': 'abc',\n",
      "                      'link': 'https://stackoverflow.com/users/1359058/abc',\n",
      "                      'profile_image': 'https://www.gravatar.com/avatar/f191024999528a3a7375f8d7181e1fe6?s=256&d=identicon&r=PG',\n",
      "                      'reputation': 10906,\n",
      "                      'user_id': 1359058,\n",
      "                      'user_type': 'registered'},\n",
      "            'question_id': 59239886,\n",
      "            'score': 5},\n",
      "           {'answer_id': 59336925,\n",
      "            'body': '<p>You could use Cython:</p>\\n'\n",
      "                    '\\n'\n",
      "                    '<pre><code>%%cython -c-O3 -c-march=native -a\\n'\n",
      "                    '#cython: language_level=3, boundscheck=False, '\n",
      "                    'wraparound=False, initializedcheck=False, cdivision=True, '\n",
      "                    'infer_types=True\\n'\n",
      "                    '\\n'\n",
      "                    'import math\\n'\n",
      "                    'import cython as cy\\n'\n",
      "                    '\\n'\n",
      "                    'cimport numpy as cnp\\n'\n",
      "                    '\\n'\n",
      "                    '\\n'\n",
      "                    'cpdef groupby_index_dict_cy(cnp.int32_t[:, :] arr):\\n'\n",
      "                    '    cdef cy.size_t size = len(arr)\\n'\n",
      "                    '    result = {}\\n'\n",
      "                    '    for i in range(size):\\n'\n",
      "                    '        key = arr[i, 0], arr[i, 1], arr[i, 2]\\n'\n",
      "                    '        if key in result:\\n'\n",
      "                    '            result[key].append(i)\\n'\n",
      "                    '        else:\\n'\n",
      "                    '            result[key] = [i]\\n'\n",
      "                    '    return result\\n'\n",
      "                    '</code></pre>\\n'\n",
      "                    '\\n'\n",
      "                    '<p>but it will not make you faster than what Pandas does, '\n",
      "                    'although it is the fastest after that (and perhaps the '\n",
      "                    '<code>numpy_index</code> based solution), and does not '\n",
      "                    'come with the memory penalty of it.\\n'\n",
      "                    'A collection of what has been proposed so far is <a '\n",
      "                    'href=\"https://colab.research.google.com/drive/1eRWXMpstnKrdeOim1HmaIm2OCAhYWQnG\" '\n",
      "                    'rel=\"nofollow noreferrer\">here</a>.</p>\\n'\n",
      "                    '\\n'\n",
      "                    \"<p>In OP's machine that should get close to ~12 sec \"\n",
      "                    'execution time.</p>\\n',\n",
      "            'content_license': 'CC BY-SA 4.0',\n",
      "            'creation_date': 1576340364,\n",
      "            'is_accepted': False,\n",
      "            'last_activity_date': 1576355701,\n",
      "            'last_edit_date': 1576355701,\n",
      "            'owner': {'accept_rate': 57,\n",
      "                      'display_name': 'norok2',\n",
      "                      'link': 'https://stackoverflow.com/users/5218354/norok2',\n",
      "                      'profile_image': 'https://lh4.googleusercontent.com/-NEO9rZKeffY/AAAAAAAAAAI/AAAAAAAAAKc/9IttO1jUOr4/photo.jpg=k-s256',\n",
      "                      'reputation': 22127,\n",
      "                      'user_id': 5218354,\n",
      "                      'user_type': 'registered'},\n",
      "            'question_id': 59239886,\n",
      "            'score': 3}],\n",
      " 'page': 1,\n",
      " 'quota_max': 300,\n",
      " 'quota_remaining': 163,\n",
      " 'total': 0}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from stackapi import StackAPI\n",
    "\n",
    "SITE = StackAPI('stackoverflow')\n",
    "\n",
    "pprint(SITE.fetch('questions/{ids}', ids=[59239886], filter='withbody'))\n",
    "pprint(SITE.fetch('questions/{ids}/answers', ids=[59239886], filter='withbody'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
